[{"categories":["Project"],"contents":"Overview cloud-benchmark is a multi-cloud benchmarking and learning project. It demonstrates how to orchestrate the deployment, execution, and cleanup of cloud resources and container workloads using modern DevOps tools. The project is designed for hands-on practice and comparison of workflows across Azure, AWS, and GCP.\nTechnologies Python: Web scraping and data modeling Azure: Blob storage, Container Registry, Container Instances Docker: Containerization of the scraper Terraform: Infrastructure as Code for resource provisioning Apache Airflow: Workflow orchestration and benchmarking Project Workflow Azure Workflow Web Scraper Development (container/):\nImplemented a Python script to scrape news articles (see scraper.py, models.py). Structured results using Pydantic models. Azure Blob Upload:\nExtended the scraper to upload results directly to Azure Blob Storage (see storage.py). Dockerization:\nContainerized the scraper application with a custom Dockerfile. Managed dependencies with requirements.txt. Terraform Infrastructure:\nDefined all required Azure resources (resource group, storage, container registry, container group) in the terraform/azure/ directory. Parameterized resource creation for staged benchmarking. Airflow Orchestration:\nCreated a DAG to automate the workflow: provision resources, push Docker image, deploy container group, monitor scraping completion, cleanup resources, and generate a markdown report. Benchmarked Azure deployment time and saved results in a project-level report. AWS Workflow (To be implemented) Provision resources on AWS (ECS/EKS, S3, etc.) Container registry setup and workflow orchestration Benchmarking and reporting GCP Workflow (To be implemented) Provision resources on GCP (Cloud Run, GCS, etc.) Container registry setup and workflow orchestration Benchmarking and reporting Setup Instructions Clone the repository\nConfigure Azure credentials\nCreate a Service Principal (SP) using Azure CLI: az ad sp create-for-rbac --name \u0026#34;cloud-benchmark-sp\u0026#34; --role=\u0026#34;Contributor\u0026#34; --scopes=\u0026#34;/subscriptions/\u0026lt;SUBSCRIPTION_ID\u0026gt;\u0026#34; This command outputs the required variables: client_id, client_secret, subscription_id, and tenant_id. Store these variables in credentials/azure.env or directly set them up in Airflow using the Connections UI or environment variables: In Airflow, set up a connection of type \u0026ldquo;Azure\u0026rdquo; and map the values as: client_id ➔ ARM_CLIENT_ID client_secret ➔ ARM_CLIENT_SECRET subscription_id ➔ ARM_SUBSCRIPTION_ID tenant_id ➔ ARM_TENANT_ID You can also use environment variables in your Airflow docker-compose.yaml for automated setup. Build and test the scraper locally (container/):\npython main.py (Requires Python 3.7+, see requirements.txt)\nBuild Docker image:\ndocker build -t cloudbenchmark-scraper container/ Run Terraform:\nConfigure .tfvars and deploy resources in terraform/azure/. Example: cd terraform/azure/ terraform init terraform apply -var-file=\u0026#34;terraform.tfvars\u0026#34; Launch Airflow environment:\nStart Airflow using Docker Compose: docker compose up -d Once Airflow is running, access the web interface and trigger the DAG for Azure benchmarking. Directory Structure cloud-benchmark/ ├── azure_run_report.md ├── container/ │ ├── Dockerfile │ ├── main.py │ ├── models.py │ ├── requirements.txt │ ├── scraper.py │ ├── storage.py ├── credentials/ │ ├── aws.env │ ├── azure.env │ ├── gcp.env │ ├── gmail.env ├── dags/ │ └── azure_workflow_dag.py ├── docker-compose.yaml ├── LICENSE ├── README.md ├── requirements.txt ├── terraform/ │ ├── aws/ │ │ └── main.tf │ ├── azure/ │ │ ├── main.tf │ │ ├── outputs.tf │ │ ├── outputs.json │ │ ├── provider.tf │ │ ├── terraform.tfvars │ │ ├── variables.tf │ │ ├── versions.tf │ ├── gcp/ │ │ └── main.tf Benchmarking and Reporting The Airflow DAG generates a markdown report (azure_run_report.md) summarizing resource details and elapsed deployment time. Reports are stored in the project root for future comparison across providers. Progress \u0026amp; Next Steps Azure workflow implemented and benchmarked Scraper container deployed and results uploaded to Azure Blob Infrastructure provisioned/destroyed via Terraform Workflow orchestrated and benchmarked with Airflow Next goals:\nImplement AWS workflow (Terraform, container registry, ECS/EKS, S3) Implement GCP workflow (Terraform, Artifact Registry, Cloud Run, GCS) Aggregate benchmark reports for all cloud providers Analyze and visualize results Polish documentation and add troubleshooting section License MIT License\nAuthor Christos\nGitHub: Christos-workspace\n","date":"January 1, 0001","hero":null,"permalink":"https://christos-workspace.github.io/docs/cloudbenchmark/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ecloud-benchmark\u003c/strong\u003e is a multi-cloud benchmarking and learning project. It demonstrates how to orchestrate the deployment, execution, and cleanup of cloud resources and container workloads using modern DevOps tools. The project is designed for hands-on practice and comparison of workflows across Azure, AWS, and GCP.\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"technologies\"\u003eTechnologies\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePython:\u003c/strong\u003e Web scraping and data modeling\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAzure:\u003c/strong\u003e Blob storage, Container Registry, Container Instances\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDocker:\u003c/strong\u003e Containerization of the scraper\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTerraform:\u003c/strong\u003e Infrastructure as Code for resource provisioning\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eApache Airflow:\u003c/strong\u003e Workflow orchestration and benchmarking\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"project-workflow\"\u003eProject Workflow\u003c/h2\u003e\n\u003ch3 id=\"azure-workflow\"\u003eAzure Workflow\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eWeb Scraper Development (\u003ccode\u003econtainer/\u003c/code\u003e):\u003c/strong\u003e\u003c/p\u003e","tags":["Project","Cloud","Azure","AWS","GCP"],"title":"Cloud Benchmark Project"},{"categories":["Website"],"contents":"Overview This site was generated using the Hugo platform, with the toha theme as a base. The site showcases my profile, skills, experiences, education, and personal/practice projects, all managed via Hugo\u0026rsquo;s content organization and the powerful configuration features of Toha.\nKey Features Modern Static Site: Fast, secure, and easily deployable anywhere. Custom Sections: About, Skills, Education, Experiences, Projects, and Documentation, each configurable via YAML files in data/sections/. Project Documentation: Each project has dedicated pages under content/docs/ (see cloudbenchmark.md for a data engineering example). Responsive Design: The Toha theme ensures good appearance on all devices. Custom Navbar \u0026amp; Sidebar: Navigation is handled via modular layouts in layouts/, with easily editable site structure. Social \u0026amp; Badges: Integrated social links, certifications, and soft skills in the About section. Easy Theming: Background, logos, and colors are customizable via theme parameters and assets. Multilingual \u0026amp; Search Support: Ready for internationalization and site-wide search (see sidebar). Structure content/ — Main markdown content, including documentation pages. data/ — Site and section configuration in YAML format. layouts/ — Custom HTML layouts and partials for theme overrides. static/ — Static assets (images, logos, etc.). .github/workflows/ — Workflow configuration for automated deployment (e.g., GitHub Pages). Usage Prerequisites Hugo (extended version recommended) Basic YAML and Markdown familiarity Running Locally git clone https://github.com/Christos-workspace/Christos-workspace.github.io.git cd Christos-workspace.github.io hugo server Browse to http://localhost:1313 to view the site.\nBuilding for Production hugo --minify The generated site will be found in the public/ directory.\nDeployment This site is published to GitHub Pages using GitHub Actions for automation. The deployment process follows the official Toha theme procedure—see the Toha guide for GitHub Pages deployment for detailed instructions.\nYou can deploy the public/ folder to any static site hosting service (e.g., GitHub Pages, Netlify, Vercel). See .github/workflows/deploy-site.yaml for an automated deployment example.\nCustomization Content: Add/edit markdown files in content/docs/, or update other sections via YAML in data/sections/. Appearance: Adjust theme logos, background, and colors via site.Params and static assets. Social \u0026amp; Badges: Update data/author.yaml and data/sections/about.yaml as needed. Theme section overrides: To customize or override various theme sections, edit or add files in the layouts/partials/ and layouts/_default/ directories as needed. Credits Hugo Static Site Generator Toha Theme All referenced images, logos, and badges remain property of their respective owners. Feel free to fork and adapt for your own portfolio!\n","date":"January 1, 0001","hero":null,"permalink":"https://christos-workspace.github.io/docs/sitedoc/","summary":"\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eThis site was generated using the \u003ca href=\"https://github.com/gohugoio/hugo\" target=\"_blank\" rel=\"noopener\"\u003eHugo\u003c/a\u003e platform,\nwith the \u003ca href=\"https://github.com/hugo-toha/toha\" target=\"_blank\" rel=\"noopener\"\u003etoha\u003c/a\u003e theme  as a base.\nThe site showcases my profile, skills, experiences, education, and personal/practice projects, all managed via Hugo\u0026rsquo;s content organization and the powerful configuration features of Toha.\u003c/p\u003e\n\u003ch3 id=\"key-features\"\u003eKey Features\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eModern Static Site:\u003c/strong\u003e Fast, secure, and easily deployable anywhere.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCustom Sections:\u003c/strong\u003e About, Skills, Education, Experiences, Projects, and Documentation, each configurable via YAML files in \u003ccode\u003edata/sections/\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eProject Documentation:\u003c/strong\u003e Each project has dedicated pages under \u003ccode\u003econtent/docs/\u003c/code\u003e (see \u003ccode\u003ecloudbenchmark.md\u003c/code\u003e for a data engineering example).\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResponsive Design:\u003c/strong\u003e The Toha theme ensures good appearance on all devices.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCustom Navbar \u0026amp; Sidebar:\u003c/strong\u003e Navigation is handled via modular layouts in \u003ccode\u003elayouts/\u003c/code\u003e, with easily editable site structure.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSocial \u0026amp; Badges:\u003c/strong\u003e Integrated social links, certifications, and soft skills in the About section.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEasy Theming:\u003c/strong\u003e Background, logos, and colors are customizable via theme parameters and assets.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMultilingual \u0026amp; Search Support:\u003c/strong\u003e Ready for internationalization and site-wide search (see sidebar).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"structure\"\u003eStructure\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econtent/\u003c/code\u003e — Main markdown content, including documentation pages.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003edata/\u003c/code\u003e — Site and section configuration in YAML format.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003elayouts/\u003c/code\u003e — Custom HTML layouts and partials for theme overrides.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003estatic/\u003c/code\u003e — Static assets (images, logos, etc.).\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e.github/workflows/\u003c/code\u003e — Workflow configuration for automated deployment (e.g., GitHub Pages).\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"usage\"\u003eUsage\u003c/h2\u003e\n\u003ch3 id=\"prerequisites\"\u003ePrerequisites\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://gohugo.io/getting-started/install/\" target=\"_blank\" rel=\"noopener\"\u003eHugo\u003c/a\u003e (extended version recommended)\u003c/li\u003e\n\u003cli\u003eBasic YAML and Markdown familiarity\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"running-locally\"\u003eRunning Locally\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit clone https://github.com/Christos-workspace/Christos-workspace.github.io.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecd Christos-workspace.github.io\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ehugo server\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBrowse to \u003ccode\u003ehttp://localhost:1313\u003c/code\u003e to view the site.\u003c/p\u003e","tags":["Website","HUGO","Toha","html\"","Markdown","YAML"],"title":"How this site was made"}]